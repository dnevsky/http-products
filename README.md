
# http-products

Согласно ТЗ в этом приложении реализовано HTTP API с единственной ручкой - `GET /`. 
При запросе на эту ручку должны возвращаться данные о продуктах с пагинацией. limit и offset передаются через query params.

Для этих данных был реализован опережающий кэш (ahead cache). Данные при обработке запроса получаются только из него.

Для роутинга запросов использовалась библиотека `gin-gonic/gin`. 
Для логирования использовалась библиотека `zap`.

Заполнение таблицы тестовыми значениями - `python million.py`.

Поднять приложение `http-products` - `make up`. Не забудьте накатить миграции и заполнить таблицу.

## `.env` переменные:

```
DB_URI="postgres://postgres:qwerty@127.0.0.1:5432/testdb?sslmode=disable"

APP_PORT = "5000"
APP_CACHE_UPDATE = 15

REDIS_ADDR="localhost:6379"
REDIS_PASSWD="asdzxc"
REDIS_DB=0

POSTGRES_DB=testdb
POSTGRES_USER=postgres
POSTGRES_PASSWORD=qwerty
```

## `Makefile`:

`make up` - поднять приложение вместе с БД и Redis.

`make build` - собрать образ приложения.

`make postgres` - поднять базу данных Postgres в Docker.

`make redis` - поднять Redis в Docker.

`make migrate` - применить миграцию.

`make shutdown` - завершение всех запущенных приложений.

`make create-migrate` - создать файлы миграции. Перед использованием нужно указать название миграции.

`make test` - запустить тесты.

`make cover` - запустить тест и показать покрытие кода тестами.

## Комментарии:

### Получение данных из базы данных

В актуальном варианте кода таблица из базы данных подгружается в приложение одним запросом скачивая абсолютно всё. Не совсем эффективное решение, но пока что так. На одном миллионе записей работает нормально. Время полного цикла обновление кэша при только заполненной базе примерно 3-5 сек, спустя итераций 10-15 время обновление около 1 секунды. Под нагрузкой время в среднем 5 сек.

Нагрузку делал с ноутбука. Нагрузка шла на ПК в рамках локальной сети при помощи jMeter. 2к соединений нарастали в течение 60 сек и потом лупили приложение на протяжении 10 минут.

### Хранение снапшота таблицы в кэше.

Поскольку мы работаем через кэш Redis нужно было придумать как хранить всю таблицу в кэше.

Самым простым вариантом который мне пришел на ум - списки в Redis. В нашем случае удобный доступ к данным.

Следующая проблема - сериализация данных для хранения. У нас сложный (относительно списка) объект, поэтому у меня было несколько вариантов.
- Либо создавать два списка и в первом хранить id, а во втором price.
- Либо создать один список и хранить в нём json строку (приложение будет тратить время на де/сериализацию данных)
- Либо создать один список и хранить в нём строку формата `id:price`.

Первый способ я не проверял, сразу показался сомнительным решением и по итогу проверок самым быстрым оказался третий способ - `id:price`.

Сериализация при помощи `json` в среднем на 0.1 секунду дольше, чем `id:price` (~1 сек против ~0.9 сек), но мы теряем удобство разработки.. Можно было бы попробовать хранить файлы protobuf, но пока не стал это использовать)

Так же недавно подсказали любопытную статью как можно хранить большие обьемы в Redis в хэш-таблице, но пока что списки с этим отлично справляются. [Storing hundreds of millions of simple key-value pairs in Redis](https://instagram-engineering.com/storing-hundreds-of-millions-of-simple-key-value-pairs-in-redis-1091ae80f74c)

### Обновление данных в кэше спустя какое-то время.

Поскольку мы работаем со списком мы не можем просто взять и заменить значения на свои по индексу. Встроенные решения Redis вроде бы не позволяют это сделать. Команда, которой можно заменить значение по индексу принимает только один индекс и одно значение, а долбить Redis 1 миллионом запросов крайне неэффективно. Поэтому я использую классический список, в которую записываю объект в формате JSON строки. Перед вставкой новых элементов я полностью удаляю products, а потом уже вставляю в список свои строки. Что-бы обеспечить атомарность я использовал транзакцию.